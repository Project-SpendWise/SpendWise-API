# Groq API Configuration
# Get your free API key at: https://console.groq.com/
GROQ_API_KEY=your-groq-api-key-here

# Groq Model Selection
# Recommended: llama-3.3-70b-versatile (best quality)
# Alternative: llama-3.1-8b-instant (faster, higher limits)
# Alternative: qwen/qwen3-32b (excellent multilingual)
GROQ_MODEL=llama-3.3-70b-versatile

# Groq API Base URL (don't change unless using custom endpoint)
GROQ_BASE_URL=https://api.groq.com/openai/v1

# Extraction Settings
MAX_TOKENS=8000
TEMPERATURE=0.1

# Batch Processing Settings
# Delay between batch requests to avoid rate limits (in seconds)
# For llama-3.3-70b: 30 RPM limit, so 3s delay = ~20 requests/min (safe)
# For llama-3.1-8b: Higher limits, can use 2s delay
BATCH_DELAY=3.0

# File Processing
MAX_FILE_SIZE_MB=50

# Batch Processing Settings
BATCH_DELAY=2.5  # Seconds between batch requests (Groq: 30 RPM = 2s minimum)
